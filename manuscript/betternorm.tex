\documentclass{article}
\usepackage[margin=2.5cm]{geometry}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{graphicx}

\title{Computing normalization factors for single-cell RNA-seq data: avoiding problems with zero counts}
\author{Aaron Lun and Karsten Bach}

\begin{document}
\maketitle

\section{Introduction}
Single-cell RNA sequencing (scRNA-seq) is a powerful technique that allows researchers to characterize the gene expression profile of single cells.
From each cell, mRNA is isolated, reverse-transcribed and subjected to massively parallel sequencing \cite{stegle2015computational}.
The sequencing reads are then mapped to a reference genome, whereby the number of reads mapped to each gene can be used to quantify the expression of that gene.
Alternatively, transcript molecules can be counted directly using unique molecular identifiers (UMIs) \cite{islam2014quantitative}.
Count data can be analyzed to identify new cell subtypes and to detect highly variable or differentially expressed (DE) genes between cell subpopulations.
This type of single-cell resolution is not possible with bulk RNA sequencing of cellular populations.
However, the downside is that the counts often contain high levels of technical noise with many ``drop-outs'', i.e., zero or near-zero values.
This is due to the difficulties in sequencing low amounts of RNA per cell, which decreases the capture efficiency during library preparation.
Moreover, the capture efficiency often varies from cell to cell, such that counts cannot be directly compared between cells.

Normalization of the scRNA-seq counts is a critical step that corrects for differences in capture efficiency between cells.
Two broad classes of normalization approaches are available -- those using spike-in RNA sets, and those using the counts for cellular RNA.
In the former, the same quantity of spike-in RNA is added to each cell prior to library preparation \cite{stegle2015computational}.
Any difference in the coverage of the spike-in transcripts must be caused by differences in capture efficiency between cells.
Normalization is then performed by scaling the counts to equalize spike-in coverage between cells.
For the methods using the cellular counts, the common assumption is that most genes are not DE across the sampled cells.
Counts are then scaled so that there is, on average, no fold-difference in expression between cells for the majority of genes.
This is the underlying concept of commonly used methods such as size factor \cite{anders2010differential} and trimmed mean of M-values (TMM) normalization \cite{robinson2010scaling}.
An even simpler approach involves scaling the counts to remove differences in library sizes between cells.

The type of normalization that can be used often depends on the characteristics of the data set.
In some data sets, spike-in data may not be present -- for example, droplet-based protocols \cite{klein2015droplet,macosko2015highly} do not allow spike-ins to be easily incorporated.
This obviously precludes the use of spike-in normalization.
The methods based on cellular counts can be applied more generally but have their own deficiencies.
Normalization by library size is insufficient when DE genes are present, as composition biases can introduce spurious differences between cells \cite{robinson2010scaling}.
Size factor or TMM normalization are more robust to DE but rely on the calculation of ratios of counts between cells.
This is not straightforward in scRNA-seq data, where the high frequency of drop-out events interferes with stable normalization.
A large number of zeroes will result in nonsensical size factors or undefined M-values in the TMM method.
One could proceed by removing the offending genes during normalization for each cell, but this may introduce biases if the number of zeroes varies across cells.

Correct normalization of scRNA-seq data is essential as it determines the validity of all downstream quantitative analyses.
In this article, we describe a deconvolution approach that improves the accuracy of the non-DE (i.e., size factor or TMM) normalization methods.
Briefly, normalization is performed on pooled counts for multiple cells, where the incidence of problematic zeroes is reduced
    -- the pooled size/normalization factors are then deconvolved back to those for the individual cells.
Using a variety of simple simulations, we demonstrate that our approach outperforms the direct application of those normalization methods for count data with many zeroes.
We also show a similar difference in behaviour on several real data sets, where deconvolved normalization yields results that are more biologically relevant.
These results suggest that our approach is a viable alternative to existing methods for general normalization of scRNA-seq data.

\section{Existing normalization methods fail with zero counts}

\subsection{The origin of zero counts in scRNA-seq data}
The high frequency of zeroes in scRNA-seq data is driven by both biological and technical aspects.
Gene expression is highly variable across cells due to cell-to-cell heterogeneity and phenomena like transcriptional bursting \cite{marinov2014singlecell}.
Such variability is likely to result in zero counts for the lowly expressed genes.
It is also technically difficult to process low quantities of input RNA into sequenceable libraries.
This results in high dropout rates whereby low-abundance transcripts are not captured during library preparation \cite{brennecke2013accounting}.

It is important to distinguish between stochastic and systematic zeroes.
Systematic zeroes refer to genes that are constitutively silent in a cell (sub)population, such that the count must be zero for all cells in that population.
These are generally not problematic as they contain no information and can be removed prior to normalization.
Stochastic zeroes refer to genes that are actively expressed but obtain counts of zero in some cells due to sampling stochasticity.
It is less clear how to deal with these genes, as they contain information about the relative differences between cells.
Removing them prior to normalization may introduce biases.

\subsection{A brief description of existing non-spike-in methods}
Here, we only consider those normalization methods not based on spike-in data.
This is motivated by the desire to obtain a general method that can be applied in all data sets.
In particular, we will review three approaches that are commonly used for RNA-seq data -- size factor, TMM and library size normalization.

Size factor normalization was originally introduced as part of the DESeq package for differential expression \cite{anders2010differential}.
It first constructs an ``average'' reference library, in which the ``count'' for each gene is defined as the geometric mean of the counts for that gene across all real libraries.
Each real library is then normalized against this average.
Specifically, for each gene, it computes the ratio of the count in each library to that in the average library.
The size factor for each library is defined as the median of this ratio across all genes.
This value represents the extent to which the counts in that library should be downscaled, 
    in order to eliminate any systematic differences in expression between libraries for the majority of (assumed) non-DE genes.

TMM normalization was introduced as part of the edgeR package for differential expression \cite{robinson2010edgeR}.
It selects one library to be a reference, and normalizes each other library against the reference.
Specifically, for each library, M-values (i.e., library size-adjusted log$_2$-ratios in expression) are computed against the reference for all genes.
The genes with the most extreme M-values are trimmed away.
High- or low-abundance genes are similarly removed.
The weighted mean of the remaining M-values is computed, where the weighting is performed according to the asymptotic variance of each M-value.
This is used to define the normalization factor for each library as $2^x$, where $x$ is the weighted mean for that library.
The normalization factor represents the downscaling required to eliminate systematic differences between libraries, additional to that required to equalize the library sizes.
Taking the product of the normalization factor and library size for each library (i.e., the effective library size) yields a value that is functionally equivalent to the size factor.

Both size factor and TMM normalization assume that most genes are not DE between libraries.
Any systematic difference in expression across the majority of genes is treated as bias.
This is duly incorporated into the size/normalization factors and removed upon scaling.
If the non-DE assumption does not hold, the computed factors will not be accurate.
In addition, both methods perform poorly in the presence of a large number of zeroes.
For size factor normalization, the geometric mean is equal to zero for genes with a zero count in any library, such that the ratios for that gene become undefined.
Conversely, a library with zero counts for many genes may have a size factor of zero, which precludes any sensible scaling.
For TMM normalization, M-values are undefined when the count in either library is zero.
In such conditions, both methods typically require \textit{ad hoc} workarounds such as the removal of zero counts within each library.

Finally, library size normalization is another commonly used approach for RNA-seq data.
This involves scaling the counts such that the library size is the same across libraries.
While simple, this approach is not robust in the presence of DE genes \cite{robinson2010scaling}.
One can imagine a scenario where a single gene is strongly upregulated in one library compared to another.
This increases the size of the first library, as more reads are generated from the upregulated gene.
Normalization by library size will then scale up the counts for the second library to compensate.
This introduces spurious differences in the counts between libraries for the non-DE genes.
The likely presence of DE in real data means that library size normalization is often inappropriate.

\subsection{Performance of existing methods on simulated data with zeroes}
To test the performance of existing methods, simulated scRNA-seq data was generated with a large number of stochastic zeros.
For gene $i$ in cell $j$, the count $y_{ij}$ was sampled from a negative binomial (NB) distribution with mean $\delta_{j}\mu_{i}$.
The $\delta_{j}$ term represents cell-specific biases (e.g., in capture efficiency) that must be normalized out, 
    and is sampled for each cell such that $\log_2(\delta_j) \sim \mathcal{N}(0, 0.25)$.
The $\mu_{i}$ term represents the expected read count for each gene, and is distributed across genes such that $\log_2(\mu_i) \sim \mbox{Uniform}(3, 6)$.
This recapitulates the spread of abundances for genes in real data.
The NB dispersion is defined for each gene as 
\[
    \varphi_i = 2 + \frac{100}{\mu_i}
\]
to represent a decreasing mean-dispersion trend.
Large values for $\varphi_i$ are consistent with the high levels of technical noise and biological heterogeneity in scRNA-seq studies,
    and ensure that a large number of stochastic zeroes are generated.
In this manner, counts were generated for 10000 genes across 800 cells.

Size factor and TMM normalization were then applied to this data set.
For size factor normalization, the geometric mean was computed by replacing all zero counts with unity.
Zero counts were also removed within each library prior to calculation of the size factor.
For TMM normalization, all undefined M-values were removed prior to trimming and calculation of the normalization factor for each library.
The corresponding size factor was defined as the effective library size, i.e., the product of the library size and the normalization factor for each library.
Estimated size factors were then compared to the true values $\delta_j$ for all cells.

Figure~\ref{fig:existing_noDE} demonstrates that both methods yield size factors that systematically deviate from the true values.
Large size factors are underestimated while small size factors are overestimated.
This is a consequence of removing stochastic zeroes prior to normalization.
Consider a simple example where a cell with low $\delta_j$ is normalized against a cell with a large $\delta_j$. 
The former cell is likely to contain more stochastic zeroes, as the mean of the sampling distribution for the counts is lower.
Removal of the affected genes will shift the median upwards among the remaining non-zero counts, resulting in overestimates of the size factor.
Similarly, the distribution of M-values will be shifted towards larger values when more zeroes are present in the smaller cell.
This is because zeroes represent sampled values below some non-zero mean, and would generally correspond to negative M-values.
Their removal increases the weighted mean and biases the estimate of the TMM normalization factor.
The converse applies to cells with large $\delta_j$, where a concomitant underestimation is observed in the size factor.
It should be stressed that the non-DE assumption has not been violated in these simulations as all genes are non-DE (other than the systematic differences due to $\delta_j$).
Even under such favourable conditions, the existing methods fail to correctly estimate the size factor for each cell.

\begin{figure}[tb]
\begin{minipage}{0.48\textwidth}
\includegraphics[width=\textwidth]{size_sim_noDE.pdf}
\subcaption{}\label{subfig:size_noDE}
\end{minipage}
\begin{minipage}{0.48\textwidth}
\includegraphics[width=\textwidth]{tmm_sim_noDE.pdf}
\subcaption{}\label{subfig:tmm_noDE}
\end{minipage}
\caption{
    Performance of existing normalization methods on the simulated data with stochastic zeroes.
    The size factor estimate for each cell is plotted against its true values for (\subref{subfig:size_noDE}) size factor and (\subref{subfig:tmm_noDE}) TMM normalization,
        using a log-scale for visibility.
    The red line represents identity between the two sets of factors.
}
\label{fig:existing_noDE}
\end{figure}


\bibliographystyle{unsrt}
\bibliography{references}



\end{document}
